{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "In this project, we have to identify the emotion from the text. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset description\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing imortant libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = '../ml/data/ISEAR.csv'\n",
    "emotion_data = pd.read_csv(dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>joy</th>\n",
       "      <th>On days when I feel close to my partner and other friends.   \\nWhen I feel at peace with myself and also experience a close  \\ncontact with people whom I regard greatly.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>fear</td>\n",
       "      <td>Every time I imagine that someone I love or I ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>anger</td>\n",
       "      <td>When I had been obviously unjustly treated and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>sadness</td>\n",
       "      <td>When I think about the short time that we live...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>disgust</td>\n",
       "      <td>At a gathering I found myself involuntarily si...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>shame</td>\n",
       "      <td>When I realized that I was directing the feeli...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0      joy  \\\n",
       "0  1     fear   \n",
       "1  2    anger   \n",
       "2  3  sadness   \n",
       "3  4  disgust   \n",
       "4  5    shame   \n",
       "\n",
       "  On days when I feel close to my partner and other friends.   \\nWhen I feel at peace with myself and also experience a close  \\ncontact with people whom I regard greatly.  \n",
       "0  Every time I imagine that someone I love or I ...                                                                                                                         \n",
       "1  When I had been obviously unjustly treated and...                                                                                                                         \n",
       "2  When I think about the short time that we live...                                                                                                                         \n",
       "3  At a gathering I found myself involuntarily si...                                                                                                                         \n",
       "4  When I realized that I was directing the feeli...                                                                                                                         "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotion_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_data_array = emotion_data.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7445, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotion_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels, sentence_collection = emotion_data_array[:, 1], emotion_data_array[:, 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Augmentation\n",
    "Since, we have not enough dataset for multiclass classification, we are using the method of text augmentation. We are using the library called, `nlpaug`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nlpaug.augmenter.word as naw\n",
    "\n",
    "from nlpaug.util import Action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before:  Every time I imagine that someone I love or I could contact a  serious illness, even death. \n",
      "After:  Every clip Ane imagine that someone 1 love or I could contact a severe illness , still death .\n",
      "\n",
      "Before:  Every time I imagine that someone I love or I could contact a  serious illness, even death. \n",
      "After:  Every time One imagine that someone 1 make out or I could contact a life threatening illness , yet death .\n",
      "\n",
      "Before:  Every time I imagine that someone I love or I could contact a  serious illness, even death. \n",
      "After:  Every prison term I imagine that someone Ane love or I could get hold of a dangerous illness , even death .\n"
     ]
    }
   ],
   "source": [
    "text = sentence_collection[0].replace(\"\\n\", \"\")\n",
    "aug = naw.SynonymAug(aug_src='wordnet')\n",
    "augmented_text = aug.augment(text)\n",
    "print(\"Before: \", text, \"\\nAfter: \", augmented_text)\n",
    "augmented_text = aug.augment(text)\n",
    "print(\"\\nBefore: \", text, \"\\nAfter: \", augmented_text)\n",
    "augmented_text = aug.augment(text)\n",
    "print(\"\\nBefore: \", text, \"\\nAfter: \", augmented_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_struc = {'emotion_label': [], 'emotion_text': []}\n",
    "aug_dataframe = pd.DataFrame(data_struc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion_label</th>\n",
       "      <th>emotion_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [emotion_label, emotion_text]\n",
       "Index: []"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aug_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we are using two augmentation techniques, namely, `synonyms augmentation` and `random word swapping`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_struc = {'emotion_label': [], 'emotion_text': []}\n",
    "aug_dataframe = pd.DataFrame(data_struc)\n",
    "for label, sentence in zip(labels, sentence_collection):\n",
    "    if sentence.find(\"\\n\") > 0:\n",
    "        sentence = sentence.replace(\"\\n\", \"\")\n",
    "        augmented_sent = aug.augment(sentence)\n",
    "        aug_dataframe = aug_dataframe.append(\n",
    "            {'emotion_label': label, 'emotion_text': sentence},\n",
    "            ignore_index=True\n",
    "        )\n",
    "        aug_dataframe = aug_dataframe.append(\n",
    "            {'emotion_label': label, 'emotion_text': augmented_sent},\n",
    "            ignore_index=True\n",
    "        )\n",
    "        augmented_sent = aug.augment(sentence)\n",
    "        aug_dataframe = aug_dataframe.append(\n",
    "            {'emotion_label': label, 'emotion_text': augmented_sent},\n",
    "            ignore_index=True\n",
    "        )\n",
    "    \n",
    "        aug1 = naw.RandomWordAug(action=\"swap\")\n",
    "        augmented_sent1 = aug1.augment(sentence)\n",
    "        aug_dataframe = aug_dataframe.append(\n",
    "            {'emotion_label': label, 'emotion_text': augmented_sent1},\n",
    "            ignore_index=True\n",
    "        )\n",
    "    else:\n",
    "        augmented_sent = aug.augment(sentence)\n",
    "        aug_dataframe = aug_dataframe.append(\n",
    "            {'emotion_label': label, 'emotion_text': sentence},\n",
    "            ignore_index=True\n",
    "        )\n",
    "        aug_dataframe = aug_dataframe.append(\n",
    "            {'emotion_label': label, 'emotion_text': augmented_sent},\n",
    "            ignore_index=True\n",
    "        )\n",
    "        augmented_sent = aug.augment(sentence)\n",
    "        aug_dataframe = aug_dataframe.append(\n",
    "            {'emotion_label': label, 'emotion_text': augmented_sent},\n",
    "            ignore_index=True\n",
    "        )\n",
    "        aug1 = naw.RandomWordAug(action=\"swap\")\n",
    "        augmented_sent1 = aug1.augment(sentence)\n",
    "        aug_dataframe = aug_dataframe.append(\n",
    "            {'emotion_label': label, 'emotion_text': augmented_sent1},\n",
    "            ignore_index=True\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_dataframe.to_csv(\"./augmented_emotion_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_array = aug_dataframe.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29780, 2)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aug_dataframe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Every time I imagine that someone I love or I could contact a  serious illness, even death.',\n",
       "       'Every time Iodine imagine that someone I love or Iodine could adjoin a serious sickness , even death .',\n",
       "       'Every time One guess that somebody Ace love operating room I could contact a serious illness , even death .',\n",
       "       ...,\n",
       "       'Once I quarrelled with my sister and after this I deliberately messed upwardly her belongings .',\n",
       "       'Erstwhile I quarrelled with my sister and after this One deliberately messed up her belongings .',\n",
       "       'Once I my quarrelled with and sister after this I deliberately messed up her . belongings'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aug_array[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels, sentence_collection = aug_array[:, 0], aug_array[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['fear', 'fear', 'fear', ..., 'guilt', 'guilt', 'guilt'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "whitespace_tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
    "treebank_tokenizer = nltk.tokenize.TreebankWordTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "whitespace_tokenized_sentences = []\n",
    "for sentence in sentence_collection:\n",
    "    whitespace_tokenized_sentences.append(\n",
    "                                    whitespace_tokenizer.tokenize(sentence)\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "treebank_tokenized_sentences = []\n",
    "for sentence in sentence_collection:\n",
    "    treebank_tokenized_sentences.append(treebank_tokenizer.tokenize(sentence))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Token normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = nltk.stem.WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatized_sentences = []\n",
    "for sentence in whitespace_tokenized_sentences:\n",
    "    lemmatized_sentences.append(\" \".join(lemmatizer.lemmatize(token.lower()) for token in sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a few back day i had a tutorial class and the teacher randomly assigned one person in each to group make a presentation . the discussion in our group had been confused the and presentation not wa very prepared well . unfortunately i wa selected to present i and could keep not calm , wa confused and result wa very poor . i felt really ashamed .'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatized_sentences[-5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "\n",
    "StopWords = set(stopwords.words('english'))\n",
    "\n",
    "preprocessed_sentences = []\n",
    "for sentence in lemmatized_sentences:\n",
    "    temp_sentence = \"\"\n",
    "    for word in sentence.split(\" \"):\n",
    "        if word in punctuation:\n",
    "            if word.find(\"!\") >= 0:\n",
    "                temp_sentence += word + \" \"\n",
    "            else:\n",
    "                pass\n",
    "        elif word not in StopWords:\n",
    "            temp_sentence += word + \" \"\n",
    "    preprocessed_sentences.append(temp_sentence.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['every time imagine someone love could contact serious illness, even death.',\n",
       " 'every time iodine imagine someone love iodine could adjoin serious sickness even death',\n",
       " 'every time one guess somebody ace love operating room could contact serious illness even death',\n",
       " 'every time imagine someone love could contact illness serious even death',\n",
       " 'obviously unjustly treated possibility elucidating this.',\n",
       " 'one obviously unjustly treat sustain possibility elucidating',\n",
       " 'obviously unjustly address give birth possibility clear',\n",
       " 'obviously unjustly treated possibility elucidating',\n",
       " 'think short time live relate period life think use short time.',\n",
       " 'call short time relate information technology time period animation think non use short time',\n",
       " 'one think brusk time live relate period life believe use myopic time',\n",
       " 'think time short live relate period life think use time short',\n",
       " 'gathering found involuntarily sitting next two people expressed opinion considered low discriminating.',\n",
       " 'gathering iodine found involuntarily sitting next two people world health organization evince opinion considered really low discriminating',\n",
       " 'gathering found involuntarily posture next two people world health organization give tongue opinion considered mouth discriminating']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_sentences[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "X_data = np.array(preprocessed_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29780,)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = OrdinalEncoder()\n",
    "encoded_label = encoder.fit_transform(X=(labels.reshape(-1, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       ...,\n",
       "       [3.],\n",
       "       [3.],\n",
       "       [3.]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_vectorizer = TfidfVectorizer()\n",
    "X_features = tf_vectorizer.fit_transform(X_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_values = X_features.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_values = encoded_label.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29780, 13075)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_values, y_values, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23824"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=5, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=1000,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=0, solver='liblinear', tol=0.0001, verbose=1,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression(verbose=1, solver='liblinear',random_state=0, C=5, penalty='l2',max_iter=1000)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.80      0.78       834\n",
      "         1.0       0.84      0.85      0.85       833\n",
      "         2.0       0.89      0.90      0.89       872\n",
      "         3.0       0.79      0.79      0.79       810\n",
      "         4.0       0.87      0.89      0.88       896\n",
      "         5.0       0.84      0.82      0.83       825\n",
      "         6.0       0.84      0.78      0.81       886\n",
      "\n",
      "    accuracy                           0.83      5956\n",
      "   macro avg       0.83      0.83      0.83      5956\n",
      "weighted avg       0.83      0.83      0.83      5956\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "accuracy_score(y_test, y_predicted)\n",
    "print(classification_report(y_test, y_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=0.8, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "nb_model = MultinomialNB(alpha=0.8)\n",
    "nb_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted = nb_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7590664875755541"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, BatchNormalization\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.constraints import max_norm\n",
    "import tensorflow.keras.backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(125, input_dim=X_values.shape[1], activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(30, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(7, activation='softmax'))\n",
    "\n",
    "sgd = SGD(lr=0.03)\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 23826 samples, validate on 5957 samples\n",
      "Epoch 1/50\n",
      "23826/23826 [==============================] - 15s 613us/sample - loss: 1.9448 - accuracy: 0.1495 - val_loss: 1.9388 - val_accuracy: 0.1450\n",
      "Epoch 2/50\n",
      "23826/23826 [==============================] - 12s 512us/sample - loss: 1.9313 - accuracy: 0.1884 - val_loss: 1.9117 - val_accuracy: 0.3824\n",
      "Epoch 3/50\n",
      "23826/23826 [==============================] - 12s 512us/sample - loss: 1.8923 - accuracy: 0.2504 - val_loss: 1.8406 - val_accuracy: 0.5034\n",
      "Epoch 4/50\n",
      "23826/23826 [==============================] - 12s 509us/sample - loss: 1.7961 - accuracy: 0.3246 - val_loss: 1.6872 - val_accuracy: 0.4460\n",
      "Epoch 5/50\n",
      "23826/23826 [==============================] - 12s 501us/sample - loss: 1.6320 - accuracy: 0.4044 - val_loss: 1.4778 - val_accuracy: 0.5179\n",
      "Epoch 6/50\n",
      "23826/23826 [==============================] - 10s 425us/sample - loss: 1.4573 - accuracy: 0.4763 - val_loss: 1.2913 - val_accuracy: 0.6005\n",
      "Epoch 7/50\n",
      "23826/23826 [==============================] - 11s 477us/sample - loss: 1.3094 - accuracy: 0.5355 - val_loss: 1.1451 - val_accuracy: 0.6552\n",
      "Epoch 8/50\n",
      "23826/23826 [==============================] - 12s 485us/sample - loss: 1.1770 - accuracy: 0.5918 - val_loss: 1.2475 - val_accuracy: 0.5649\n",
      "Epoch 9/50\n",
      "23826/23826 [==============================] - 12s 490us/sample - loss: 1.0609 - accuracy: 0.6338 - val_loss: 0.9183 - val_accuracy: 0.7129\n",
      "Epoch 10/50\n",
      "23826/23826 [==============================] - 12s 501us/sample - loss: 0.9629 - accuracy: 0.6751 - val_loss: 0.9120 - val_accuracy: 0.6925\n",
      "Epoch 11/50\n",
      "23826/23826 [==============================] - 12s 501us/sample - loss: 0.8642 - accuracy: 0.7126 - val_loss: 0.7824 - val_accuracy: 0.7838\n",
      "Epoch 12/50\n",
      "23826/23826 [==============================] - 12s 484us/sample - loss: 0.7827 - accuracy: 0.7389 - val_loss: 0.7645 - val_accuracy: 0.7514\n",
      "Epoch 13/50\n",
      "23826/23826 [==============================] - 12s 501us/sample - loss: 0.7151 - accuracy: 0.7701 - val_loss: 0.6091 - val_accuracy: 0.8221\n",
      "Epoch 14/50\n",
      "23826/23826 [==============================] - 12s 500us/sample - loss: 0.6612 - accuracy: 0.7880 - val_loss: 0.5451 - val_accuracy: 0.8440\n",
      "Epoch 15/50\n",
      "23826/23826 [==============================] - 12s 499us/sample - loss: 0.5970 - accuracy: 0.8102 - val_loss: 0.6265 - val_accuracy: 0.7876\n",
      "Epoch 16/50\n",
      "23826/23826 [==============================] - 12s 493us/sample - loss: 0.5528 - accuracy: 0.8241 - val_loss: 0.5008 - val_accuracy: 0.8504\n",
      "Epoch 17/50\n",
      "23826/23826 [==============================] - 12s 498us/sample - loss: 0.5041 - accuracy: 0.8417 - val_loss: 0.5267 - val_accuracy: 0.8459\n",
      "Epoch 18/50\n",
      "23826/23826 [==============================] - 12s 517us/sample - loss: 0.4719 - accuracy: 0.8547 - val_loss: 0.6048 - val_accuracy: 0.8098\n",
      "Epoch 19/50\n",
      "23826/23826 [==============================] - 12s 507us/sample - loss: 0.4448 - accuracy: 0.8604 - val_loss: 0.3800 - val_accuracy: 0.8988\n",
      "Epoch 20/50\n",
      "23826/23826 [==============================] - 12s 497us/sample - loss: 0.4119 - accuracy: 0.8716 - val_loss: 0.4042 - val_accuracy: 0.8882\n",
      "Epoch 21/50\n",
      "23826/23826 [==============================] - 12s 496us/sample - loss: 0.3767 - accuracy: 0.8856 - val_loss: 0.3494 - val_accuracy: 0.9078\n",
      "Epoch 22/50\n",
      "23826/23826 [==============================] - 12s 493us/sample - loss: 0.3632 - accuracy: 0.8882 - val_loss: 0.4116 - val_accuracy: 0.8723\n",
      "Epoch 23/50\n",
      "23826/23826 [==============================] - 12s 521us/sample - loss: 0.3396 - accuracy: 0.8967 - val_loss: 0.3303 - val_accuracy: 0.9144\n",
      "Epoch 24/50\n",
      "23826/23826 [==============================] - 13s 546us/sample - loss: 0.3255 - accuracy: 0.9020 - val_loss: 0.2891 - val_accuracy: 0.9228\n",
      "Epoch 25/50\n",
      "23826/23826 [==============================] - 12s 500us/sample - loss: 0.3003 - accuracy: 0.9087 - val_loss: 0.2911 - val_accuracy: 0.9241\n",
      "Epoch 26/50\n",
      "23826/23826 [==============================] - 12s 501us/sample - loss: 0.2949 - accuracy: 0.9099 - val_loss: 0.3847 - val_accuracy: 0.8872\n",
      "Epoch 27/50\n",
      "23826/23826 [==============================] - 12s 496us/sample - loss: 0.2797 - accuracy: 0.9137 - val_loss: 0.7143 - val_accuracy: 0.7739\n",
      "Epoch 28/50\n",
      "23826/23826 [==============================] - 12s 504us/sample - loss: 0.2692 - accuracy: 0.9186 - val_loss: 0.2525 - val_accuracy: 0.9312\n",
      "Epoch 29/50\n",
      "23826/23826 [==============================] - 12s 507us/sample - loss: 0.2465 - accuracy: 0.9256 - val_loss: 0.2664 - val_accuracy: 0.9352\n",
      "Epoch 30/50\n",
      "23826/23826 [==============================] - 12s 495us/sample - loss: 0.2470 - accuracy: 0.9235 - val_loss: 0.2434 - val_accuracy: 0.9370\n",
      "Epoch 31/50\n",
      "23826/23826 [==============================] - 12s 500us/sample - loss: 0.2385 - accuracy: 0.9266 - val_loss: 0.2639 - val_accuracy: 0.9330\n",
      "Epoch 32/50\n",
      "23826/23826 [==============================] - 12s 503us/sample - loss: 0.2138 - accuracy: 0.9353 - val_loss: 0.2463 - val_accuracy: 0.9335\n",
      "Epoch 33/50\n",
      "23826/23826 [==============================] - 12s 507us/sample - loss: 0.2224 - accuracy: 0.9315 - val_loss: 0.2355 - val_accuracy: 0.9424\n",
      "Epoch 34/50\n",
      "23826/23826 [==============================] - 12s 506us/sample - loss: 0.2049 - accuracy: 0.9385 - val_loss: 0.2383 - val_accuracy: 0.9392\n",
      "Epoch 35/50\n",
      "23826/23826 [==============================] - 12s 500us/sample - loss: 0.1977 - accuracy: 0.9392 - val_loss: 0.2819 - val_accuracy: 0.9335\n",
      "Epoch 36/50\n",
      "23826/23826 [==============================] - 12s 498us/sample - loss: 0.1956 - accuracy: 0.9399 - val_loss: 0.2364 - val_accuracy: 0.9389\n",
      "Epoch 37/50\n",
      "23826/23826 [==============================] - 12s 502us/sample - loss: 0.1874 - accuracy: 0.9432 - val_loss: 0.2388 - val_accuracy: 0.9407\n",
      "Epoch 38/50\n",
      "23826/23826 [==============================] - 12s 500us/sample - loss: 0.1870 - accuracy: 0.9417 - val_loss: 0.2403 - val_accuracy: 0.9389\n",
      "Epoch 39/50\n",
      "23826/23826 [==============================] - 12s 506us/sample - loss: 0.1806 - accuracy: 0.9440 - val_loss: 0.2601 - val_accuracy: 0.9335\n",
      "Epoch 40/50\n",
      "23826/23826 [==============================] - 12s 498us/sample - loss: 0.1656 - accuracy: 0.9488 - val_loss: 0.2469 - val_accuracy: 0.9409\n",
      "Epoch 41/50\n",
      "23826/23826 [==============================] - 12s 494us/sample - loss: 0.1700 - accuracy: 0.9474 - val_loss: 0.2430 - val_accuracy: 0.9391\n",
      "Epoch 42/50\n",
      "23826/23826 [==============================] - 13s 560us/sample - loss: 0.1597 - accuracy: 0.9519 - val_loss: 0.2467 - val_accuracy: 0.9350\n",
      "Epoch 43/50\n",
      "23826/23826 [==============================] - 13s 526us/sample - loss: 0.1588 - accuracy: 0.9508 - val_loss: 0.2443 - val_accuracy: 0.9407\n",
      "Epoch 44/50\n",
      "23826/23826 [==============================] - 13s 526us/sample - loss: 0.1575 - accuracy: 0.9516 - val_loss: 0.2560 - val_accuracy: 0.9344\n",
      "Epoch 45/50\n",
      "23826/23826 [==============================] - 13s 529us/sample - loss: 0.1452 - accuracy: 0.9560 - val_loss: 0.2478 - val_accuracy: 0.9421\n",
      "Epoch 46/50\n",
      "23826/23826 [==============================] - 12s 524us/sample - loss: 0.1504 - accuracy: 0.9547 - val_loss: 0.2581 - val_accuracy: 0.9412\n",
      "Epoch 47/50\n",
      "23826/23826 [==============================] - 12s 518us/sample - loss: 0.1430 - accuracy: 0.9540 - val_loss: 0.2746 - val_accuracy: 0.9402\n",
      "Epoch 48/50\n",
      "23826/23826 [==============================] - 13s 548us/sample - loss: 0.1429 - accuracy: 0.9551 - val_loss: 0.5759 - val_accuracy: 0.8375\n",
      "Epoch 49/50\n",
      "23826/23826 [==============================] - 12s 521us/sample - loss: 0.1438 - accuracy: 0.9557 - val_loss: 0.2553 - val_accuracy: 0.9424\n",
      "Epoch 50/50\n",
      "23826/23826 [==============================] - 12s 518us/sample - loss: 0.1356 - accuracy: 0.9586 - val_loss: 0.2814 - val_accuracy: 0.9360\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f9f2043d198>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=50, batch_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svc_model = SVC()\n",
    "svc_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(91.68, 0.5, 'predicted label')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_mat = confusion_matrix(y_test, y_predicted)\n",
    "sns.heatmap(confusion_mat.T, square=True, annot=True, fmt='d', cbar=False)\n",
    "plt.xlabel('true label')\n",
    "plt.ylabel('predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "print(metrics.accuracy_score(y_test, test_label))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
